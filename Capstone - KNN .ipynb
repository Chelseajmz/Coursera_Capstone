{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Loan Performance - CJ ", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "This notebook practices the Classification - KNN (K-th nearest neighbor of learning) for the Week 6 Capstone project within IBM - Machine Learning with Python \nFile Start: 09/28/2019 11am ET \nAuthor: Chelsea Jiang ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Data Processing", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Import Coding Packages \nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \n%matplotlib inline"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-09-29 15:30:59--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.193\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.193|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 23101 (23K) [text/csv]\nSaving to: \u2018loan_train.csv\u2019\n\n100%[======================================>] 23,101      --.-K/s   in 0.002s  \n\n2019-09-29 15:30:59 (12.4 MB/s) - \u2018loan_train.csv\u2019 saved [23101/23101]\n\n"
                }
            ], 
            "source": "# Download Dataset \n!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
        }, 
        {
            "source": "### Load Data from CSV File (df)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Load Data from the CSV File - df \ndf = pd.read_csv('loan_train.csv')"
        }, 
        {
            "source": "### Process Data from CSV File (df)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Data Processing - Convert Date time object (effective date and due date) - *** KEEPING Column names!\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf['due_date'] = pd.to_datetime(df['due_date'])"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Data Processing - Day of week (by effective date) \n## Categorize by \"weekend = 1\" (vs. weekday)\ndf['dayofweek'] = df['effective_date'].dt.dayofweek \ndf['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Data Processing - To numerical values (gender coding: FEMALE = 1)\n## do NOT rerun - ONLY RUN THIS ONCE, because it is using Replace \ndf['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bachelor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bachelor  High School or Below  \\\n0       1000     30   45       0        0         0                     1   \n1       1000     30   33       1        0         1                     0   \n2       1000     15   27       0        0         0                     0   \n3       1000     30   28       1        1         0                     0   \n4       1000     30   29       0        1         0                     0   \n\n   college  \n0        0  \n1        0  \n2        1  \n3        1  \n4        1  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "## Data Processing - One hot coding Education (drop one, correct typo) \nFeature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.rename(columns={'Bechalor':'Bachelor'},inplace = True)\nFeature.head()"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## Data Processing - Feature Selection (define X (feature set), y (loan_status))\nX = Feature\ny = df['loan_status'].values"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  from ipykernel import kernelapp as app\n"
                }
            ], 
            "source": "## Data Normalization (norm/fit X)\nX = preprocessing.StandardScaler().fit(X).transform(X)"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set: (276, 8) (276,)\nTest set: (70, 8) (70,)\n"
                }
            ], 
            "source": "## Train Test Split \n## change Test size selection? not 0.2? \nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)                        "
        }, 
        {
            "source": "## Classification - K nearest neighbor (KNN)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "By Jaccard Index, the best accuracy is 0.78571 with K = 6\nBy F1-Score, the best accuracy is 0.66298 with K = 7\n"
                }
            ], 
            "source": "## KNN - Import Library \nfrom sklearn.neighbors import KNeighborsClassifier\n\n## KNN - Training and plotting best K for each accuracy evaluation  \nKs = 20\nJC = np.zeros((Ks-1))\nF1 = np.zeros((Ks-1))\nfor k in range(1,Ks):\n    nb  = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)\n    yhat = nb.predict(X_test)\n    JC[k-1] =  metrics.jaccard_similarity_score(y_test, yhat, normalize=True)\n    F1[k-1] = metrics.f1_score(y_test, yhat,average = 'macro')\nprint('By Jaccard Index, the best accuracy is', round(JC.max(),5), 'with K =', JC.argmax())\nprint('By F1-Score, the best accuracy is', round(F1.max(),5), 'with K =', F1.argmax())\n\n## (??) Log loss is not applicable as the result is categorical instead of continuous probability? "
        }, 
        {
            "source": "## Classification - Decision Tree ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "By Jaccard Index, accuracy of the decision tree is 0.61429\nBy F1-Score, accuracy of the decision tree is, 0.48571\n"
                }
            ], 
            "source": "## Decision Tree - Import Library \nfrom sklearn.tree import DecisionTreeClassifier\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 3)\n#print ('Train set:', X_train.shape,  y_train.shape)\n#print ('Test set:', X_test.shape,  y_test.shape)   \n## Creating an instance of the decision tree DT and Train it \n\nDT = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\nDT.fit(X_train, y_train)\n## Predictions using the tree \nPT = DT.predict(X_test)\n\n## Accuracy of the Tree \nJC =  metrics.jaccard_similarity_score(y_test, yhat, normalize=True)\nF1 = metrics.f1_score(y_test, yhat,average = 'macro')\nprint('By Jaccard Index, accuracy of the decision tree is', round(JC ,5))\nprint('By F1-Score, accuracy of the decision tree is,', round(F1,5))"
        }, 
        {
            "source": "## Support Vector Machine", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X = np.asarray(Feature)\ny = np.asarray(df['loan_status'])\ny[0:5]\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "By Jaccard Index, accuracy of the SVM with Kernel  linear is 0.78571\nBy F1-Score, accuracy of the SVM with Kernel  linear is 0.44\n"
                }
            ], 
            "source": "## Testing different SVM kernels \n# RBF \nfrom sklearn import svm\nfor kernel in ('linear', 'poly', 'rbf'):\n    clf = svm.SVC(kernel=kernel)\n    clf.fit(X_train, y_train)\n    yhat = clf.predict(X_test)\n\n    ## Accuracy of the Tree \n    JC =  metrics.jaccard_similarity_score(y_test, yhat, normalize=True)\n    F1 = metrics.f1_score(y_test, yhat,average = 'macro')\n    print('By Jaccard Index, accuracy of the SVM with Kernel ',kernel,  'is', round(JC ,5))\n    print('By F1-Score, accuracy of the SVM with Kernel ', kernel,  'is', round(F1 ,5))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Linear"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Polynomial "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Sigmoid "
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}